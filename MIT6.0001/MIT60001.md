Origin: https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-0001-introduction-to-computer-science-and-programming-in-python-fall-2016/

## Lecture 1 - Introduction

Computers do two things:

- Perform calculations
- Store results

Declarative vs. Imperative knowledge:

- Declarative knowledge is factual knowledge
- Imperative knowledge is HOW to do something

A program is a sequence of <u>definitions</u> (which are evaluated) and <u>commands</u> (which are executed).

## Lecture 2 - Branching and Iteration

Starts with **string concatenation**, and using `print` function with comma or + concatenation

**Control flow** branching and boolean truth tables.

|       |      |       |       |
| ----- | ---- | ----- | ----- |
| True  | and  | True  | True  |
| True  | and  | False | False |
| False | and  | True  | False |
| False | and  | False | False |
| True  |  or  | True  | True  |
| True  |  or  | False | True  |
| False |  or  | True  | True  |
| False |  or  | False | False |

**While loops** and **for loops**, range function and break statements

- Use `for` loops when number of iterations are known, `while` loops when this is not known
- Can use `while` loop in place of a  `for` loop but not vice versa

## Lecture 3- String Manipulation and Basic Algorithms

String functions and manipulation: **len()**, square bracket notation for slicing and substrings

**Immutability**: a string object cannot be modified once created

**Guess and Check** algorithm:

- A guess and check algorithm is basically brute force. For a cube root finder, loop through all numbers until the desired answer is found.

**Approximate Solution** algorithm:

- The major characteristic of the approximate algorithm solution is an **epsilon** value and a **delta**. We keep increasing the current guess by the delta, until we run out of guesses or an answer within epsilon is reached.		

**Bisection** (or **Binary**) search:

- Search midway, if too high then eliminate upper half of the search space. Otherwise,			    eliminate lower half of the serach space. Continue until search space runs out or answer is found.



## Lecture 4 - Decomposition, Abstraction and Functions

**Decomposition**: construct complex functionality from smaller portions - creating organization in your code

**Abstraction**: abstract away the details for a method - make into black box - suppressing unnecessary details

Functions have:

- **Name**
- **Parameters**, or **arguments** (0 or more)
- **Docstring** - (optional) describes how to use the function; provides abstraction
- **Body** - the code for the function; Python functions start with `def`
- Return value (optional; if not included then `return None` is added)

Function **scope**: making a function call creates a new scope. This scope is discarded when the function call is complete.

Scoping rules dictate that a function creates a local scope for itself before anything else (if `x` is declared in function *and* outside it, the outside `x` will not be affected by the inside `x`). However, the function *can* access a global variable if it doesn't have a variable with the same name as the global variable. LEGB scoping rule for Python: 

- Local
- Enclosed
- Global
- Built-in

## Lecture 5 - Tuples, Lists, Mutability and Cloning

Compound data types are made up of other data types

**Tuples** - contain immutable complex elements. Used for **swapping variables**, or to return **multiple values** from a function. Tuple destructuring

**Lists** - similar to tuples, but mutable. Accessing by index, *append* method and *extend* method. Concatenation using + operator. Remove elements *remove* method and *pop* method. *Sort* (for sorting in place), *sorted* (for creating a sorted copy) and the *reverse* methods. Using *for loops* for looping over list elements.

Splitting strings to lists (`list(str)`), string *join* method

Lists are mutable - when you copy them by `a = b` then `b` is only an alias to the original list. Shallow copy a list by `b = a[:]`. This is called **aliasing**.



## Lecture 6 - Recursion and Dictionaries

**Recursion** - repeating items in a self-repeating way. The opposite of recursion is an **iterative** algorithm (such as `for` or `while` loops). Recusion is a **divide and conquer** algorithm. Reduce a complex problem to: (a very easy problem + slightly simpler problem). Critical to have a **base case** - to prevent infinite recursion.

Examples for recursion: Factorial / multiplication / Fibonacci sequence

**Dictionaries** and iterables (such as range function or `dict.keys()`). Python dictionary keys need to be immutable.

Dictionaries permit **memoization**.



## Lecture 7 - Testing, Debugging, Exceptions, and Assertions

Three classes of tests:

- **Unit tests** - each function runs according to specification
- **Regression tests** - add tests for new bugs to test suite (so new fixes don't introduce the same bug as was previously solved)
- **Integration tests** - does the program as a whole work
- **Blackbox testing** - testing based on just function's docstring
- **Glassbox testing** - writing tests to functions based on code (test extremes, edge cases, etc.)

**Exception** are errors that occur at runtime. Python offers exception **handlers** (`try/except` blocks).

**Assertions** - assert statements exist in functions to state that expectations of what is coming into the function are what they should be. If an assertion fails, the function does not continue.

```python
def func():
	assert not len(some_list) == 0, 'message to print if fails'
  # do something else
```

## Lecture 8 - Object Oriented Programming

Everything is an object in Python. Objects are **data abstractions**. It's key to have abstraction because implementation details are trivial, but objects provide **decomposition** and **abstraction** via giving:

1. **Internal representation** (data for representing - attributes)
2. **Interface** (how to interact with an object - methods)

Garbage collection - garbage collector reclaims "dead" objects to reclaim memory.

**Classes** and the difference between creating a class and instantiating a class, to make instance variables. Dot notation can be used to access attributes and methods.

```python
class Coordinate(object):
	def __init__(self, x):
		self.x = x
```

Special methods such as:

- `__str__`
- `__init__`
- `__add__`  and `__sub__` and`__eq__`

The `isinstance()` special builtin function gets whether an object is an instance of a class.

## Lecture 9 - Object Oriented Programming II

**Random OOP Topics **

​		**ADT** - abstract data types are implemented via classes (non)

​		**Class variables** can be used to track things like unique IDs

​		Getters and setters are critical in good OOP

​		**Default arguments** for functions

**Inheritance** - inheritance permits heirarchies. Overwriting methods, `super` method for calling parent's instantiator, missing `__init__` (meaning it takes it from the parent). Methods not found in subclass will be searched for in the (grand)-parent class(es).

## Lecture 10 - Algorithmic Efficiency

Tradeoff between space and time - **memoization** speeds up computations at the expense of some storage.

Three ways to timing **efficiency**:

1. **Time it** - varies by computer / varies by implementation (# of iterations, etc.) / answer for small runs is not scalable to larger datasets
2. **Count # of Operations** (+-/*><=, etc) - still depends on implementation / definition of operation is ambiguous
3. **Asymptotic Notation**

The essence of the question is - *how does the problem behave when the size of the input increases* . This is answered by **Big O** notation.

There are three possibilities. For example, searching through a list will have a **best case**, **worst case**, and an **average case** scenario. Typically we care about the worst case scenario.

Additive and multiplicative constants are ignored in Big O, as they don't matter at large *n* values. Moreover, only the **dominant** term is kept. `O(log n)` is better/faster than `O(n)`.

Two Rules:

- When adding two O values, they add: `O(n) + O(n*n) = O(n + n^2) = O(n^2)` 
- When doing multiplication (like in a loop), they multiply: `O(n) * O(n) = O(n^2)`

| Complexity | description |
| ---------- | ----------- |
| O(1)       | Constant    |
| O(log n)   | Logarithmic |
| O(n)       | Linear      |
| O(n log n) | Log linear  |
| O(n^c)     | Polynomial  |
| O(c^n)     | Exponential |

## Lecture 11 - Algorithmic Efficiency II

This lecture give examples of various algorithms with their running times



**Constant Complexity O(1)**:

		- Complexity independent of size of input

**Logarithmic Complexity O(log n)**:

*This algorithm occurs for those algos that go down by a fraction each iteration.*

- Binary search or other *divide and conquer* algorithms
- Integer to string converter (`while` loop dividing `i /= 10` each iteration)

**Linear O(n)**:

*Occurs for algos wherein the size of the problem decreases by 1 each iteration.*

- Basic string searching for substring
- Linear search on unsorted list (must look at each element)
- Factorial calculator

**Log Linear O(n log n)**:

- Good sorting algorithms (Mergesort or Quicksort)

**Polynomials O(n^2)**:

*Typically loop nested within a loop*

- Poor sorting algorithms



- Nested loops

**Exponential O(2^n)**:

When a recursive function call itself twice in each call*

- Fibonacci sequence recursive algorithm
- Towers of Hanoi recursive algorithm

## Lecture 12 - Searching and Sorting

Exhaustive searching, or **brute force searching** (`O(n)` complexity)

**Bisection search** is faster but requires search being sorted (`O(log n)` complexity). Search requires sorting, so sorting is covered next.

-----

**Bubble Sort** - "bubble" through list twice, and swap when things. Need an *inner loop* for comparisons, and an *outer loop* for multiple passes . Complexity is `O(n^2)`

**Selection Sort** - Find smallest element, move to front. Find second smallest, etc. Also `O(n^2)`

**Mergesort** - split list in half until you get lists of 0 or 1 elements. *Base case* is that 0 or 1 element lists are considered sorted. Then merge the lists by picking the smaller of the two first elements (first elem is the shortest as the pieces are sorted). This is `O(n log n)`

**Quicksort** - pick a pivot, partition, sort the halves, then rejoin the (two sides + pivot). Base case is list of size 1, which is sorted. This is `O(n log n)` also.

- Fibonacci sequence recursive algorithm
- Towers of Hanoi recursive algorithm
- 